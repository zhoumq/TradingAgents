"""
é˜¿é‡Œç™¾ç‚¼ OpenAIå…¼å®¹é€‚é…å™¨
ä¸º TradingAgents æä¾›é˜¿é‡Œç™¾ç‚¼å¤§æ¨¡å‹çš„ OpenAI å…¼å®¹æ¥å£
æ”¯æŒåŸç”Ÿ Function Calling å’Œå®Œæ•´çš„ LangChain é›†æˆ
"""

import os
from typing import Any, Dict, List, Optional, Union, Sequence
from langchain_openai import ChatOpenAI
from langchain_core.tools import BaseTool
from langchain_core.utils.function_calling import convert_to_openai_tool
from pydantic import Field, SecretStr
from ..config.config_manager import token_tracker


class ChatDashScopeOpenAI(ChatOpenAI):
    """
    é˜¿é‡Œç™¾ç‚¼ OpenAI å…¼å®¹é€‚é…å™¨
    ç»§æ‰¿ ChatOpenAIï¼Œé€šè¿‡ OpenAI å…¼å®¹æ¥å£è°ƒç”¨ç™¾ç‚¼æ¨¡å‹
    æ”¯æŒåŸç”Ÿ Function Calling å’Œå·¥å…·è°ƒç”¨
    """
    
    def __init__(self, **kwargs):
        """åˆå§‹åŒ– DashScope OpenAI å…¼å®¹å®¢æˆ·ç«¯"""
        
        # è®¾ç½® DashScope OpenAI å…¼å®¹æ¥å£çš„é»˜è®¤é…ç½®
        kwargs.setdefault("base_url", "https://dashscope.aliyuncs.com/compatible-mode/v1")
        kwargs.setdefault("api_key", os.getenv("DASHSCOPE_API_KEY"))
        kwargs.setdefault("model", "qwen-turbo")
        kwargs.setdefault("temperature", 0.1)
        kwargs.setdefault("max_tokens", 2000)
        
        # æ£€æŸ¥ API å¯†é’¥
        if not kwargs.get("api_key"):
            raise ValueError(
                "DashScope API key not found. Please set DASHSCOPE_API_KEY environment variable "
                "or pass api_key parameter."
            )
        
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(**kwargs)

        print(f"âœ… é˜¿é‡Œç™¾ç‚¼ OpenAI å…¼å®¹é€‚é…å™¨åˆå§‹åŒ–æˆåŠŸ")
        print(f"   æ¨¡å‹: {kwargs.get('model', 'qwen-turbo')}")

        # å…¼å®¹ä¸åŒç‰ˆæœ¬çš„å±æ€§å
        api_base = getattr(self, 'base_url', None) or getattr(self, 'openai_api_base', None) or kwargs.get('base_url', 'unknown')
        print(f"   API Base: {api_base}")
    
    def _generate(self, *args, **kwargs):
        """é‡å†™ç”Ÿæˆæ–¹æ³•ï¼Œæ·»åŠ  token ä½¿ç”¨é‡è¿½è¸ª"""
        
        # è°ƒç”¨çˆ¶ç±»çš„ç”Ÿæˆæ–¹æ³•
        result = super()._generate(*args, **kwargs)
        
        # å°è¯•è¿½è¸ª token ä½¿ç”¨é‡
        try:
            # ä»ç»“æœä¸­æå– token ä½¿ç”¨ä¿¡æ¯
            if hasattr(result, 'llm_output') and result.llm_output:
                token_usage = result.llm_output.get('token_usage', {})
                
                input_tokens = token_usage.get('prompt_tokens', 0)
                output_tokens = token_usage.get('completion_tokens', 0)
                
                if input_tokens > 0 or output_tokens > 0:
                    # ç”Ÿæˆä¼šè¯ID
                    session_id = kwargs.get('session_id', f"dashscope_openai_{hash(str(args))%10000}")
                    analysis_type = kwargs.get('analysis_type', 'stock_analysis')
                    
                    # ä½¿ç”¨ TokenTracker è®°å½•ä½¿ç”¨é‡
                    token_tracker.track_usage(
                        provider="dashscope",
                        model_name=self.model_name,
                        input_tokens=input_tokens,
                        output_tokens=output_tokens,
                        session_id=session_id,
                        analysis_type=analysis_type
                    )
                    
        except Exception as track_error:
            # token è¿½è¸ªå¤±è´¥ä¸åº”è¯¥å½±å“ä¸»è¦åŠŸèƒ½
            print(f"âš ï¸ Token è¿½è¸ªå¤±è´¥: {track_error}")
        
        return result
    
    def bind_tools(
        self,
        tools: Sequence[Union[Dict[str, Any], type, BaseTool]],
        **kwargs: Any,
    ) -> "ChatDashScopeOpenAI":
        """
        ç»‘å®šå·¥å…·åˆ°æ¨¡å‹
        ä½¿ç”¨ OpenAI å…¼å®¹çš„ Function Calling æ ¼å¼
        """
        
        # è½¬æ¢å·¥å…·ä¸º OpenAI æ ¼å¼
        formatted_tools = []
        for tool in tools:
            if hasattr(tool, "name") and hasattr(tool, "description"):
                # è¿™æ˜¯ä¸€ä¸ª BaseTool å®ä¾‹
                try:
                    openai_tool = convert_to_openai_tool(tool)
                    formatted_tools.append(openai_tool)
                except Exception as e:
                    print(f"âš ï¸ å·¥å…·è½¬æ¢å¤±è´¥: {tool.name} - {e}")
                    continue
            elif isinstance(tool, dict):
                formatted_tools.append(tool)
            else:
                # å°è¯•è½¬æ¢ä¸º OpenAI å·¥å…·æ ¼å¼
                try:
                    formatted_tools.append(convert_to_openai_tool(tool))
                except Exception as e:
                    print(f"âš ï¸ å·¥å…·è½¬æ¢å¤±è´¥: {tool} - {e}")
                    continue
        
        print(f"ğŸ”§ ç»‘å®š {len(formatted_tools)} ä¸ªå·¥å…·åˆ°é˜¿é‡Œç™¾ç‚¼æ¨¡å‹")
        
        # è°ƒç”¨çˆ¶ç±»çš„ bind_tools æ–¹æ³•
        return super().bind_tools(formatted_tools, **kwargs)


# æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
DASHSCOPE_OPENAI_MODELS = {
    # é€šä¹‰åƒé—®ç³»åˆ—
    "qwen-turbo": {
        "description": "é€šä¹‰åƒé—® Turbo - å¿«é€Ÿå“åº”ï¼Œé€‚åˆæ—¥å¸¸å¯¹è¯",
        "context_length": 8192,
        "supports_function_calling": True,
        "recommended_for": ["å¿«é€Ÿä»»åŠ¡", "æ—¥å¸¸å¯¹è¯", "ç®€å•åˆ†æ"]
    },
    "qwen-plus": {
        "description": "é€šä¹‰åƒé—® Plus - å¹³è¡¡æ€§èƒ½å’Œæˆæœ¬",
        "context_length": 32768,
        "supports_function_calling": True,
        "recommended_for": ["å¤æ‚åˆ†æ", "ä¸“ä¸šä»»åŠ¡", "æ·±åº¦æ€è€ƒ"]
    },
    "qwen-plus-latest": {
        "description": "é€šä¹‰åƒé—® Plus æœ€æ–°ç‰ˆ - æœ€æ–°åŠŸèƒ½å’Œæ€§èƒ½",
        "context_length": 32768,
        "supports_function_calling": True,
        "recommended_for": ["æœ€æ–°åŠŸèƒ½", "å¤æ‚åˆ†æ", "ä¸“ä¸šä»»åŠ¡"]
    },
    "qwen-max": {
        "description": "é€šä¹‰åƒé—® Max - æœ€å¼ºæ€§èƒ½",
        "context_length": 32768,
        "supports_function_calling": True,
        "recommended_for": ["æœ€å¤æ‚ä»»åŠ¡", "ä¸“ä¸šåˆ†æ", "é«˜è´¨é‡è¾“å‡º"]
    },
    "qwen-max-latest": {
        "description": "é€šä¹‰åƒé—® Max æœ€æ–°ç‰ˆ - æœ€å¼ºæ€§èƒ½æœ€æ–°ç‰ˆ",
        "context_length": 32768,
        "supports_function_calling": True,
        "recommended_for": ["æœ€å¤æ‚ä»»åŠ¡", "æœ€æ–°åŠŸèƒ½", "é¡¶çº§æ€§èƒ½"]
    }
}


def get_available_openai_models() -> Dict[str, Dict[str, Any]]:
    """è·å–å¯ç”¨çš„ DashScope OpenAI å…¼å®¹æ¨¡å‹åˆ—è¡¨"""
    return DASHSCOPE_OPENAI_MODELS


def create_dashscope_openai_llm(
    model: str = "qwen-plus-latest",
    api_key: Optional[str] = None,
    temperature: float = 0.1,
    max_tokens: int = 2000,
    **kwargs
) -> ChatDashScopeOpenAI:
    """åˆ›å»º DashScope OpenAI å…¼å®¹ LLM å®ä¾‹çš„ä¾¿æ·å‡½æ•°"""
    
    return ChatDashScopeOpenAI(
        model=model,
        api_key=api_key,
        temperature=temperature,
        max_tokens=max_tokens,
        **kwargs
    )


def test_dashscope_openai_connection(
    model: str = "qwen-turbo",
    api_key: Optional[str] = None
) -> bool:
    """æµ‹è¯• DashScope OpenAI å…¼å®¹æ¥å£è¿æ¥"""
    
    try:
        from langchain_core.messages import HumanMessage
        
        llm = create_dashscope_openai_llm(
            model=model,
            api_key=api_key,
            max_tokens=50
        )
        
        # æµ‹è¯•ç®€å•è°ƒç”¨
        response = llm.invoke([HumanMessage(content="è¯·å›å¤'è¿æ¥æµ‹è¯•æˆåŠŸ'")])
        
        if "æˆåŠŸ" in response.content:
            print(f"âœ… DashScope OpenAI å…¼å®¹æ¥å£è¿æ¥æµ‹è¯•æˆåŠŸ")
            print(f"   æ¨¡å‹: {model}")
            print(f"   å“åº”: {response.content}")
            return True
        else:
            print(f"âš ï¸ DashScope OpenAI å…¼å®¹æ¥å£å“åº”å¼‚å¸¸: {response.content}")
            return False
            
    except Exception as e:
        print(f"âŒ DashScope OpenAI å…¼å®¹æ¥å£è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_dashscope_openai_function_calling(
    model: str = "qwen-plus-latest",
    api_key: Optional[str] = None
) -> bool:
    """æµ‹è¯• DashScope OpenAI å…¼å®¹æ¥å£çš„ Function Calling"""
    
    try:
        from langchain_core.messages import HumanMessage
        from langchain_core.tools import tool
        
        # å®šä¹‰æµ‹è¯•å·¥å…·
        @tool
        def get_test_data(query: str) -> str:
            """è·å–æµ‹è¯•æ•°æ®çš„å·¥å…·"""
            return f"æµ‹è¯•æ•°æ®: {query}"
        
        # åˆ›å»º LLM å¹¶ç»‘å®šå·¥å…·
        llm = create_dashscope_openai_llm(
            model=model,
            api_key=api_key,
            max_tokens=200
        )
        
        llm_with_tools = llm.bind_tools([get_test_data])
        
        # æµ‹è¯•å·¥å…·è°ƒç”¨
        response = llm_with_tools.invoke([
            HumanMessage(content="è¯·è°ƒç”¨get_test_dataå·¥å…·ï¼Œå‚æ•°ä¸º'function calling test'")
        ])
        
        if hasattr(response, 'tool_calls') and len(response.tool_calls) > 0:
            print(f"âœ… DashScope OpenAI Function Calling æµ‹è¯•æˆåŠŸ")
            print(f"   å·¥å…·è°ƒç”¨æ•°é‡: {len(response.tool_calls)}")
            print(f"   å·¥å…·è°ƒç”¨: {response.tool_calls[0]['name']}")
            return True
        else:
            print(f"âš ï¸ DashScope OpenAI Function Calling æœªè§¦å‘")
            print(f"   å“åº”å†…å®¹: {response.content}")
            return False
            
    except Exception as e:
        print(f"âŒ DashScope OpenAI Function Calling æµ‹è¯•å¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    """æµ‹è¯•è„šæœ¬"""
    print("ğŸ§ª DashScope OpenAI å…¼å®¹é€‚é…å™¨æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•è¿æ¥
    connection_ok = test_dashscope_openai_connection()
    
    if connection_ok:
        # æµ‹è¯• Function Calling
        function_calling_ok = test_dashscope_openai_function_calling()
        
        if function_calling_ok:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼DashScope OpenAI å…¼å®¹é€‚é…å™¨å·¥ä½œæ­£å¸¸")
        else:
            print("\nâš ï¸ Function Calling æµ‹è¯•å¤±è´¥")
    else:
        print("\nâŒ è¿æ¥æµ‹è¯•å¤±è´¥")
