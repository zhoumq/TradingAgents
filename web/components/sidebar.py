"""
ä¾§è¾¹æ ç»„ä»¶
"""

import streamlit as st
import os

def render_sidebar():
    """æ¸²æŸ“ä¾§è¾¹æ é…ç½®"""
    
    with st.sidebar:
        st.header("ğŸ”§ ç³»ç»Ÿé…ç½®")
        
        # APIå¯†é’¥çŠ¶æ€
        st.subheader("ğŸ”‘ APIå¯†é’¥çŠ¶æ€")
        
        dashscope_key = os.getenv("DASHSCOPE_API_KEY")
        finnhub_key = os.getenv("FINNHUB_API_KEY")
        
        if dashscope_key:
            st.success(f"âœ… é˜¿é‡Œç™¾ç‚¼: {dashscope_key[:12]}...")
        else:
            st.error("âŒ é˜¿é‡Œç™¾ç‚¼: æœªé…ç½®")
        
        if finnhub_key:
            st.success(f"âœ… é‡‘èæ•°æ®: {finnhub_key[:12]}...")
        else:
            st.error("âŒ é‡‘èæ•°æ®: æœªé…ç½®")
        
        st.markdown("---")
        
        # AIæ¨¡å‹é…ç½®
        st.subheader("ğŸ§  AIæ¨¡å‹é…ç½®")

        # LLMæä¾›å•†é€‰æ‹©
        llm_provider = st.selectbox(
            "é€‰æ‹©LLMæä¾›å•†",
            options=["dashscope", "google"],
            index=0,
            format_func=lambda x: {
                "dashscope": "é˜¿é‡Œç™¾ç‚¼ - å›½äº§æ¨¡å‹",
                "google": "Google AI - Geminiæ¨¡å‹"
            }[x],
            help="é€‰æ‹©AIæ¨¡å‹æä¾›å•†"
        )

        # æ ¹æ®æä¾›å•†æ˜¾ç¤ºä¸åŒçš„æ¨¡å‹é€‰é¡¹
        if llm_provider == "dashscope":
            llm_model = st.selectbox(
                "é€‰æ‹©é˜¿é‡Œç™¾ç‚¼æ¨¡å‹",
                options=["qwen-turbo", "qwen-plus", "qwen-max"],
                index=1,
                format_func=lambda x: {
                    "qwen-turbo": "é€šä¹‰åƒé—® Turbo - å¿«é€Ÿå“åº”",
                    "qwen-plus": "é€šä¹‰åƒé—® Plus - å¹³è¡¡æ€§èƒ½",
                    "qwen-max": "é€šä¹‰åƒé—® Max - æœ€å¼ºæ€§èƒ½"
                }[x],
                help="é€‰æ‹©ç”¨äºåˆ†æçš„é˜¿é‡Œç™¾ç‚¼æ¨¡å‹"
            )
        else:  # google
            llm_model = st.selectbox(
                "é€‰æ‹©Googleæ¨¡å‹",
                options=["gemini-2.0-flash", "gemini-1.5-pro", "gemini-1.5-flash"],
                index=0,
                format_func=lambda x: {
                    "gemini-2.0-flash": "Gemini 2.0 Flash - æ¨èä½¿ç”¨",
                    "gemini-1.5-pro": "Gemini 1.5 Pro - å¼ºå¤§æ€§èƒ½",
                    "gemini-1.5-flash": "Gemini 1.5 Flash - å¿«é€Ÿå“åº”"
                }[x],
                help="é€‰æ‹©ç”¨äºåˆ†æçš„Google Geminiæ¨¡å‹"
            )
        
        # é«˜çº§è®¾ç½®
        with st.expander("âš™ï¸ é«˜çº§è®¾ç½®"):
            enable_memory = st.checkbox(
                "å¯ç”¨è®°å¿†åŠŸèƒ½",
                value=False,
                help="å¯ç”¨æ™ºèƒ½ä½“è®°å¿†åŠŸèƒ½ï¼ˆå¯èƒ½å½±å“æ€§èƒ½ï¼‰"
            )
            
            enable_debug = st.checkbox(
                "è°ƒè¯•æ¨¡å¼",
                value=False,
                help="å¯ç”¨è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯è¾“å‡º"
            )
            
            max_tokens = st.slider(
                "æœ€å¤§è¾“å‡ºé•¿åº¦",
                min_value=1000,
                max_value=8000,
                value=4000,
                step=500,
                help="AIæ¨¡å‹çš„æœ€å¤§è¾“å‡ºtokenæ•°é‡"
            )
        
        st.markdown("---")
        
        # ç³»ç»Ÿä¿¡æ¯
        st.subheader("â„¹ï¸ ç³»ç»Ÿä¿¡æ¯")
        
        st.info("""
        **ç‰ˆæœ¬**: 1.0.0
        **æ¡†æ¶**: Streamlit + LangGraph
        **AIæ¨¡å‹**: é˜¿é‡Œç™¾ç‚¼é€šä¹‰åƒé—®
        **æ•°æ®æº**: FinnHub API
        """)
        
        # å¸®åŠ©é“¾æ¥
        st.subheader("ğŸ“š å¸®åŠ©èµ„æº")
        
        st.markdown("""
        - [ğŸ“– ä½¿ç”¨æ–‡æ¡£](https://github.com/TauricResearch/TradingAgents)
        - [ğŸ› é—®é¢˜åé¦ˆ](https://github.com/TauricResearch/TradingAgents/issues)
        - [ğŸ’¬ è®¨è®ºç¤¾åŒº](https://github.com/TauricResearch/TradingAgents/discussions)
        - [ğŸ”§ APIå¯†é’¥é…ç½®](../docs/security/api_keys_security.md)
        """)
    
    return {
        'llm_provider': llm_provider,
        'llm_model': llm_model,
        'enable_memory': enable_memory,
        'enable_debug': enable_debug,
        'max_tokens': max_tokens
    }
