# æ•°æ®æºé›†æˆ (v0.1.6)

## æ¦‚è¿°

TradingAgents ä¸­æ–‡å¢å¼ºç‰ˆé›†æˆäº†å¤šç§é‡‘èæ•°æ®æºï¼Œç‰¹åˆ«åŠ å¼ºäº†å¯¹ä¸­å›½Aè‚¡å¸‚åœºçš„æ”¯æŒã€‚ä¸ºæ™ºèƒ½ä½“æä¾›å…¨é¢ã€å‡†ç¡®ã€å®æ—¶çš„å¸‚åœºä¿¡æ¯ã€‚æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº†æ”¯æŒçš„æ•°æ®æºã€APIé›†æˆæ–¹æ³•ã€æ•°æ®æ ¼å¼å’Œä½¿ç”¨æŒ‡å—ã€‚

## ğŸ”„ v0.1.6 é‡å¤§æ›´æ–°

### æ•°æ®æºè¿ç§»å®Œæˆ
- âœ… **ä¸»æ•°æ®æº**: ä»é€šè¾¾ä¿¡å®Œå…¨è¿ç§»åˆ°Tushare
- âœ… **æ··åˆç­–ç•¥**: Tushare(å†å²æ•°æ®) + AKShare(å®æ—¶æ•°æ®)
- âœ… **ç»Ÿä¸€æ¥å£**: é€æ˜çš„æ•°æ®æºåˆ‡æ¢ï¼Œç”¨æˆ·æ— æ„ŸçŸ¥
- âœ… **å‘åå…¼å®¹**: ä¿æŒæ‰€æœ‰APIæ¥å£ä¸å˜
- âœ… **ç”¨æˆ·ç•Œé¢**: æ‰€æœ‰æç¤ºä¿¡æ¯å·²æ›´æ–°ä¸ºæ­£ç¡®çš„æ•°æ®æºæ ‡è¯†

## ğŸ¯ v0.1.6 æ•°æ®æºçŠ¶æ€

| æ•°æ®æº | å¸‚åœº | çŠ¶æ€ | è¯´æ˜ |
|--------|------|------|------|
| ğŸ‡¨ğŸ‡³ **Tushareæ•°æ®æ¥å£** | Aè‚¡ | âœ… å®Œæ•´æ”¯æŒ | å®æ—¶è¡Œæƒ…ã€å†å²æ•°æ®ã€æŠ€æœ¯æŒ‡æ ‡ |
| **FinnHub** | ç¾è‚¡ | âœ… å®Œæ•´æ”¯æŒ | å®æ—¶æ•°æ®ã€åŸºæœ¬é¢ã€æ–°é—» |
| **Google News** | å…¨çƒ | âœ… å®Œæ•´æ”¯æŒ | è´¢ç»æ–°é—»ã€å¸‚åœºèµ„è®¯ |
| **Reddit** | å…¨çƒ | âœ… å®Œæ•´æ”¯æŒ | ç¤¾äº¤åª’ä½“æƒ…ç»ªåˆ†æ |
| **MongoDB** | ç¼“å­˜ | âœ… å®Œæ•´æ”¯æŒ | æ•°æ®æŒä¹…åŒ–å­˜å‚¨ |
| **Redis** | ç¼“å­˜ | âœ… å®Œæ•´æ”¯æŒ | é«˜é€Ÿæ•°æ®ç¼“å­˜ |

## æ”¯æŒçš„æ•°æ®æº

### ğŸ‡¨ğŸ‡³ 1. Tushareæ•°æ®æ¥å£ (æ–°å¢ v0.1.3)

#### ç®€ä»‹
Tushareæ•°æ®æ¥å£æ˜¯ä¸­å›½é¢†å…ˆçš„è‚¡ç¥¨æ•°æ®æä¾›å•†ï¼Œä¸ºAè‚¡å¸‚åœºæä¾›å®æ—¶è¡Œæƒ…å’Œå†å²æ•°æ®ã€‚

#### æ•°æ®ç±»å‹
```python
tdx_data_types = {
    "å®æ—¶æ•°æ®": [
        "Aè‚¡å®æ—¶è¡Œæƒ…",
        "æˆäº¤é‡",
        "æ¶¨è·Œå¹…",
        "æ¢æ‰‹ç‡"
    ],
    "å†å²æ•°æ®": [
        "æ—¥Kçº¿æ•°æ®",
        "åˆ†é’Ÿçº§æ•°æ®",
        "å¤æƒæ•°æ®",
        "é™¤æƒé™¤æ¯"
    ],
    "æŠ€æœ¯æŒ‡æ ‡": [
        "MAç§»åŠ¨å¹³å‡",
        "MACD",
        "RSI",
        "KDJ"
    ],
    "å¸‚åœºæ•°æ®": [
        "æ¿å—åˆ†ç±»",
        "æ¦‚å¿µè‚¡",
        "é¾™è™æ¦œ",
        "èµ„é‡‘æµå‘"
    ]
}
```

#### ä½¿ç”¨ç¤ºä¾‹
```python
from tradingagents.dataflows.tdx_utils import get_stock_data

# è·å–Aè‚¡æ•°æ®
data = get_stock_data(
    stock_code="000001",  # å¹³å®‰é“¶è¡Œ
    start_date="2024-01-01",
    end_date="2024-12-31"
)
```

### 1. FinnHub API

#### ç®€ä»‹
FinnHub æ˜¯é¢†å…ˆçš„é‡‘èæ•°æ®æä¾›å•†ï¼Œæä¾›å®æ—¶è‚¡ç¥¨ä»·æ ¼ã€å…¬å¸åŸºæœ¬é¢æ•°æ®ã€æ–°é—»å’Œå¸‚åœºæŒ‡æ ‡ã€‚

#### æ•°æ®ç±»å‹
```python
finnhub_data_types = {
    "å®æ—¶æ•°æ®": [
        "è‚¡ç¥¨ä»·æ ¼",
        "äº¤æ˜“é‡",
        "å¸‚åœºæ·±åº¦",
        "å®æ—¶æ–°é—»"
    ],
    "åŸºæœ¬é¢æ•°æ®": [
        "è´¢åŠ¡æŠ¥è¡¨",
        "å…¬å¸æ¦‚å†µ",
        "åˆ†æå¸ˆè¯„çº§",
        "ç›ˆåˆ©é¢„æµ‹"
    ],
    "æŠ€æœ¯æŒ‡æ ‡": [
        "RSI",
        "MACD",
        "å¸ƒæ—å¸¦",
        "ç§»åŠ¨å¹³å‡çº¿"
    ],
    "å¸‚åœºæ•°æ®": [
        "IPOæ—¥å†",
        "åˆ†çº¢ä¿¡æ¯",
        "è‚¡ç¥¨åˆ†å‰²",
        "æœŸæƒæ•°æ®"
    ]
}
```

#### API é…ç½®
```python
# finnhub_utils.py
import finnhub

class FinnHubDataProvider:
    """FinnHub æ•°æ®æä¾›å™¨"""
    
    def __init__(self, api_key: str):
        self.client = finnhub.Client(api_key=api_key)
        self.rate_limiter = RateLimiter(calls_per_minute=60)  # å…è´¹ç‰ˆé™åˆ¶
    
    def get_stock_price(self, symbol: str) -> Dict:
        """è·å–è‚¡ç¥¨ä»·æ ¼"""
        with self.rate_limiter:
            quote = self.client.quote(symbol)
            return {
                "symbol": symbol,
                "current_price": quote.get("c"),
                "change": quote.get("d"),
                "change_percent": quote.get("dp"),
                "high": quote.get("h"),
                "low": quote.get("l"),
                "open": quote.get("o"),
                "previous_close": quote.get("pc"),
                "timestamp": quote.get("t")
            }
    
    def get_company_profile(self, symbol: str) -> Dict:
        """è·å–å…¬å¸æ¦‚å†µ"""
        with self.rate_limiter:
            profile = self.client.company_profile2(symbol=symbol)
            return {
                "symbol": symbol,
                "name": profile.get("name"),
                "industry": profile.get("finnhubIndustry"),
                "sector": profile.get("gsubind"),
                "market_cap": profile.get("marketCapitalization"),
                "shares_outstanding": profile.get("shareOutstanding"),
                "website": profile.get("weburl"),
                "logo": profile.get("logo"),
                "exchange": profile.get("exchange")
            }
    
    def get_financial_statements(self, symbol: str, statement_type: str = "ic") -> Dict:
        """è·å–è´¢åŠ¡æŠ¥è¡¨"""
        with self.rate_limiter:
            financials = self.client.financials(symbol, statement_type, "annual")
            return {
                "symbol": symbol,
                "statement_type": statement_type,
                "data": financials.get("financials", []),
                "currency": financials.get("currency"),
                "last_updated": financials.get("cik")
            }
```

#### ä½¿ç”¨ç¤ºä¾‹
```python
# åˆå§‹åŒ– FinnHub å®¢æˆ·ç«¯
finnhub_provider = FinnHubDataProvider(api_key=os.getenv("FINNHUB_API_KEY"))

# è·å–è‚¡ç¥¨ä»·æ ¼
price_data = finnhub_provider.get_stock_price("AAPL")
print(f"AAPL å½“å‰ä»·æ ¼: ${price_data['current_price']}")

# è·å–å…¬å¸ä¿¡æ¯
company_info = finnhub_provider.get_company_profile("AAPL")
print(f"å…¬å¸åç§°: {company_info['name']}")
```

### 2. Yahoo Finance

#### ç®€ä»‹
Yahoo Finance æä¾›å…è´¹çš„å†å²è‚¡ç¥¨æ•°æ®ã€è´¢åŠ¡ä¿¡æ¯å’Œå¸‚åœºæŒ‡æ ‡ï¼Œæ˜¯è·å–å†å²æ•°æ®çš„ä¼˜ç§€é€‰æ‹©ã€‚

#### æ•°æ®ç±»å‹
```python
yahoo_finance_data_types = {
    "å†å²æ•°æ®": [
        "è‚¡ç¥¨ä»·æ ¼å†å²",
        "äº¤æ˜“é‡å†å²",
        "è°ƒæ•´åä»·æ ¼",
        "è‚¡æ¯å†å²"
    ],
    "è´¢åŠ¡æ•°æ®": [
        "æŸç›Šè¡¨",
        "èµ„äº§è´Ÿå€ºè¡¨",
        "ç°é‡‘æµé‡è¡¨",
        "å…³é”®æŒ‡æ ‡"
    ],
    "å¸‚åœºæ•°æ®": [
        "æœŸæƒé“¾",
        "åˆ†æå¸ˆå»ºè®®",
        "æœºæ„æŒè‚¡",
        "å†…éƒ¨äººäº¤æ˜“"
    ]
}
```

#### API é›†æˆ
```python
# yfin_utils.py
import yfinance as yf
import pandas as pd

class YahooFinanceProvider:
    """Yahoo Finance æ•°æ®æä¾›å™¨"""
    
    def __init__(self):
        self.cache = {}
        self.cache_duration = 300  # 5åˆ†é’Ÿç¼“å­˜
    
    def get_historical_data(self, symbol: str, period: str = "1y") -> pd.DataFrame:
        """è·å–å†å²æ•°æ®"""
        cache_key = f"{symbol}_{period}"
        
        if self._is_cache_valid(cache_key):
            return self.cache[cache_key]["data"]
        
        ticker = yf.Ticker(symbol)
        hist_data = ticker.history(period=period)
        
        # ç¼“å­˜æ•°æ®
        self.cache[cache_key] = {
            "data": hist_data,
            "timestamp": time.time()
        }
        
        return hist_data
    
    def get_financial_info(self, symbol: str) -> Dict:
        """è·å–è´¢åŠ¡ä¿¡æ¯"""
        ticker = yf.Ticker(symbol)
        info = ticker.info
        
        return {
            "symbol": symbol,
            "market_cap": info.get("marketCap"),
            "enterprise_value": info.get("enterpriseValue"),
            "pe_ratio": info.get("trailingPE"),
            "pb_ratio": info.get("priceToBook"),
            "debt_to_equity": info.get("debtToEquity"),
            "roe": info.get("returnOnEquity"),
            "revenue_growth": info.get("revenueGrowth"),
            "profit_margins": info.get("profitMargins"),
            "beta": info.get("beta")
        }
    
    def get_technical_indicators(self, symbol: str, period: str = "1y") -> Dict:
        """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡"""
        hist_data = self.get_historical_data(symbol, period)
        
        # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
        hist_data["MA_20"] = hist_data["Close"].rolling(window=20).mean()
        hist_data["MA_50"] = hist_data["Close"].rolling(window=50).mean()
        
        # è®¡ç®— RSI
        hist_data["RSI"] = self._calculate_rsi(hist_data["Close"])
        
        # è®¡ç®— MACD
        macd_data = self._calculate_macd(hist_data["Close"])
        hist_data = pd.concat([hist_data, macd_data], axis=1)
        
        return {
            "symbol": symbol,
            "indicators": hist_data.tail(1).to_dict("records")[0],
            "trend_analysis": self._analyze_trend(hist_data),
            "support_resistance": self._find_support_resistance(hist_data)
        }
```

### 3. Reddit API

#### ç®€ä»‹
Reddit API æä¾›ç¤¾äº¤åª’ä½“è®¨è®ºæ•°æ®ï¼Œç”¨äºåˆ†ææŠ•èµ„è€…æƒ…ç»ªå’Œå¸‚åœºçƒ­ç‚¹ã€‚

#### æ•°æ®ç±»å‹
```python
reddit_data_types = {
    "è®¨è®ºæ•°æ®": [
        "çƒ­é—¨å¸–å­",
        "è¯„è®ºå†…å®¹",
        "ç”¨æˆ·äº’åŠ¨",
        "è¯é¢˜è¶‹åŠ¿"
    ],
    "æƒ…æ„Ÿæ•°æ®": [
        "æƒ…æ„Ÿææ€§",
        "æƒ…æ„Ÿå¼ºåº¦",
        "æƒ…æ„Ÿåˆ†å¸ƒ",
        "æƒ…æ„Ÿå˜åŒ–"
    ],
    "çƒ­åº¦æŒ‡æ ‡": [
        "æåŠé¢‘ç‡",
        "è®¨è®ºçƒ­åº¦",
        "ç”¨æˆ·å‚ä¸åº¦",
        "ä¼ æ’­é€Ÿåº¦"
    ]
}
```

#### API é›†æˆ
```python
# reddit_utils.py
import praw
from textblob import TextBlob

class RedditDataProvider:
    """Reddit æ•°æ®æä¾›å™¨"""
    
    def __init__(self, client_id: str, client_secret: str, user_agent: str):
        self.reddit = praw.Reddit(
            client_id=client_id,
            client_secret=client_secret,
            user_agent=user_agent
        )
        self.sentiment_analyzer = SentimentAnalyzer()
    
    def get_stock_discussions(self, symbol: str, subreddit: str = "stocks", limit: int = 100) -> List[Dict]:
        """è·å–è‚¡ç¥¨è®¨è®º"""
        discussions = []
        
        # æœç´¢ç›¸å…³å¸–å­
        for submission in self.reddit.subreddit(subreddit).search(symbol, limit=limit):
            # åˆ†ææƒ…æ„Ÿ
            sentiment = self.sentiment_analyzer.analyze(submission.title + " " + submission.selftext)
            
            discussions.append({
                "id": submission.id,
                "title": submission.title,
                "content": submission.selftext,
                "score": submission.score,
                "num_comments": submission.num_comments,
                "created_utc": submission.created_utc,
                "author": str(submission.author),
                "url": submission.url,
                "sentiment": sentiment
            })
        
        return discussions
    
    def analyze_sentiment_trends(self, discussions: List[Dict]) -> Dict:
        """åˆ†ææƒ…æ„Ÿè¶‹åŠ¿"""
        if not discussions:
            return {"error": "No discussions found"}
        
        # è®¡ç®—æ•´ä½“æƒ…æ„Ÿ
        sentiments = [d["sentiment"]["polarity"] for d in discussions]
        avg_sentiment = sum(sentiments) / len(sentiments)
        
        # æ—¶é—´åºåˆ—åˆ†æ
        time_series = self._create_sentiment_time_series(discussions)
        
        # çƒ­åº¦åˆ†æ
        engagement_metrics = self._calculate_engagement_metrics(discussions)
        
        return {
            "overall_sentiment": avg_sentiment,
            "sentiment_distribution": self._calculate_sentiment_distribution(sentiments),
            "time_series": time_series,
            "engagement_metrics": engagement_metrics,
            "trending_topics": self._extract_trending_topics(discussions)
        }
```

### 4. Google News

#### ç®€ä»‹
Google News API æä¾›å®æ—¶æ–°é—»æ•°æ®ï¼Œç”¨äºåˆ†æå¸‚åœºäº‹ä»¶å’Œæ–°é—»å¯¹è‚¡ä»·çš„å½±å“ã€‚

#### æ•°æ®ç±»å‹
```python
google_news_data_types = {
    "æ–°é—»å†…å®¹": [
        "æ–°é—»æ ‡é¢˜",
        "æ–°é—»æ­£æ–‡",
        "å‘å¸ƒæ—¶é—´",
        "æ–°é—»æ¥æº"
    ],
    "å½±å“åˆ†æ": [
        "æ–°é—»æƒ…æ„Ÿ",
        "å½±å“ç¨‹åº¦",
        "ç›¸å…³æ€§è¯„åˆ†",
        "æ—¶æ•ˆæ€§åˆ†æ"
    ],
    "äº‹ä»¶è¿½è¸ª": [
        "äº‹ä»¶æ—¶é—´çº¿",
        "å…³è”äº‹ä»¶",
        "å½±å“èŒƒå›´",
        "åç»­å‘å±•"
    ]
}
```

#### API é›†æˆ
```python
# googlenews_utils.py
from GoogleNews import GoogleNews
import requests
from bs4 import BeautifulSoup

class GoogleNewsProvider:
    """Google News æ•°æ®æä¾›å™¨"""
    
    def __init__(self):
        self.googlenews = GoogleNews()
        self.sentiment_analyzer = SentimentAnalyzer()
    
    def get_stock_news(self, symbol: str, days: int = 7) -> List[Dict]:
        """è·å–è‚¡ç¥¨ç›¸å…³æ–°é—»"""
        # è®¾ç½®æœç´¢å‚æ•°
        self.googlenews.clear()
        self.googlenews.set_time_range(f"{days}d")
        self.googlenews.set_lang("en")
        
        # æœç´¢æ–°é—»
        search_terms = [symbol, f"{symbol} stock", f"{symbol} earnings"]
        all_news = []
        
        for term in search_terms:
            self.googlenews.search(term)
            news_results = self.googlenews.results()
            
            for news in news_results:
                # è·å–æ–°é—»è¯¦æƒ…
                news_detail = self._get_news_detail(news)
                if news_detail:
                    all_news.append(news_detail)
        
        # å»é‡å’Œæ’åº
        unique_news = self._deduplicate_news(all_news)
        return sorted(unique_news, key=lambda x: x["published_date"], reverse=True)
    
    def _get_news_detail(self, news_item: Dict) -> Dict:
        """è·å–æ–°é—»è¯¦æƒ…"""
        try:
            # åˆ†ææ–°é—»æƒ…æ„Ÿ
            sentiment = self.sentiment_analyzer.analyze(news_item.get("title", ""))
            
            # è¯„ä¼°æ–°é—»é‡è¦æ€§
            importance = self._assess_news_importance(news_item)
            
            return {
                "title": news_item.get("title"),
                "link": news_item.get("link"),
                "published_date": news_item.get("date"),
                "source": news_item.get("media"),
                "sentiment": sentiment,
                "importance": importance,
                "relevance_score": self._calculate_relevance_score(news_item)
            }
        except Exception as e:
            print(f"Error processing news item: {e}")
            return None
    
    def analyze_news_impact(self, news_list: List[Dict], symbol: str) -> Dict:
        """åˆ†ææ–°é—»å½±å“"""
        if not news_list:
            return {"error": "No news found"}
        
        # æƒ…æ„Ÿåˆ†æ
        sentiment_analysis = self._analyze_news_sentiment(news_list)
        
        # å½±å“è¯„ä¼°
        impact_assessment = self._assess_news_impact(news_list, symbol)
        
        # æ—¶é—´çº¿åˆ†æ
        timeline_analysis = self._create_news_timeline(news_list)
        
        return {
            "sentiment_analysis": sentiment_analysis,
            "impact_assessment": impact_assessment,
            "timeline_analysis": timeline_analysis,
            "key_events": self._identify_key_events(news_list),
            "market_implications": self._analyze_market_implications(news_list, symbol)
        }
```

## æ•°æ®é›†æˆæ¥å£

### ç»Ÿä¸€æ•°æ®æ¥å£
```python
# interface.py
class DataInterface:
    """ç»Ÿä¸€æ•°æ®æ¥å£"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.providers = self._initialize_providers()
        self.cache_manager = CacheManager()
        
    def _initialize_providers(self) -> Dict:
        """åˆå§‹åŒ–æ•°æ®æä¾›å™¨"""
        providers = {}
        
        # FinnHub
        if self.config.get("finnhub_api_key"):
            providers["finnhub"] = FinnHubDataProvider(self.config["finnhub_api_key"])
        
        # Yahoo Finance
        providers["yahoo"] = YahooFinanceProvider()
        
        # Reddit
        if self.config.get("reddit_credentials"):
            providers["reddit"] = RedditDataProvider(**self.config["reddit_credentials"])
        
        # Google News
        providers["google_news"] = GoogleNewsProvider()
        
        return providers
    
    def get_comprehensive_data(self, symbol: str, date: str = None) -> Dict:
        """è·å–ç»¼åˆæ•°æ®"""
        data = {}
        
        # å¹¶è¡Œè·å–æ•°æ®
        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = {
                executor.submit(self._get_price_data, symbol): "price_data",
                executor.submit(self._get_fundamental_data, symbol): "fundamental_data",
                executor.submit(self._get_news_data, symbol): "news_data",
                executor.submit(self._get_social_data, symbol): "social_data"
            }
            
            for future in as_completed(futures):
                data_type = futures[future]
                try:
                    data[data_type] = future.result()
                except Exception as e:
                    print(f"Error fetching {data_type}: {e}")
                    data[data_type] = {}
        
        return data
    
    def _get_price_data(self, symbol: str) -> Dict:
        """è·å–ä»·æ ¼æ•°æ®"""
        # ä¼˜å…ˆä½¿ç”¨ FinnHubï¼Œå¤‡ç”¨ Yahoo Finance
        if "finnhub" in self.providers:
            try:
                return self.providers["finnhub"].get_stock_price(symbol)
            except Exception:
                pass
        
        if "yahoo" in self.providers:
            hist_data = self.providers["yahoo"].get_historical_data(symbol, "5d")
            latest = hist_data.iloc[-1]
            return {
                "symbol": symbol,
                "current_price": latest["Close"],
                "change": latest["Close"] - latest["Open"],
                "high": latest["High"],
                "low": latest["Low"],
                "volume": latest["Volume"]
            }
        
        return {}
```

## æ•°æ®è´¨é‡æ§åˆ¶

### æ•°æ®éªŒè¯
```python
class DataValidator:
    """æ•°æ®éªŒè¯å™¨"""
    
    def validate_data(self, data: Dict, data_type: str) -> Tuple[bool, List[str]]:
        """éªŒè¯æ•°æ®è´¨é‡"""
        errors = []
        
        # åŸºæœ¬å®Œæ•´æ€§æ£€æŸ¥
        if not data:
            errors.append("Data is empty")
            return False, errors
        
        # ç‰¹å®šç±»å‹éªŒè¯
        if data_type == "price_data":
            errors.extend(self._validate_price_data(data))
        elif data_type == "fundamental_data":
            errors.extend(self._validate_fundamental_data(data))
        elif data_type == "news_data":
            errors.extend(self._validate_news_data(data))
        elif data_type == "social_data":
            errors.extend(self._validate_social_data(data))
        
        return len(errors) == 0, errors
    
    def _validate_price_data(self, data: Dict) -> List[str]:
        """éªŒè¯ä»·æ ¼æ•°æ®"""
        errors = []
        
        required_fields = ["symbol", "current_price"]
        for field in required_fields:
            if field not in data:
                errors.append(f"Missing required field: {field}")
        
        # ä»·æ ¼åˆç†æ€§æ£€æŸ¥
        if "current_price" in data:
            price = data["current_price"]
            if not isinstance(price, (int, float)) or price <= 0:
                errors.append("Invalid price value")
        
        return errors
```

## ä½¿ç”¨æœ€ä½³å®è·µ

### 1. API é™åˆ¶ç®¡ç†
```python
class RateLimiter:
    """API é™åˆ¶ç®¡ç†å™¨"""
    
    def __init__(self, calls_per_minute: int):
        self.calls_per_minute = calls_per_minute
        self.calls = []
    
    def __enter__(self):
        current_time = time.time()
        
        # æ¸…ç†è¿‡æœŸçš„è°ƒç”¨è®°å½•
        self.calls = [call_time for call_time in self.calls if current_time - call_time < 60]
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
        if len(self.calls) >= self.calls_per_minute:
            sleep_time = 60 - (current_time - self.calls[0])
            if sleep_time > 0:
                time.sleep(sleep_time)
        
        self.calls.append(current_time)
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        pass
```

### 2. é”™è¯¯å¤„ç†å’Œé‡è¯•
```python
def with_retry(max_retries: int = 3, delay: float = 1.0):
    """é‡è¯•è£…é¥°å™¨"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_retries - 1:
                        raise e
                    time.sleep(delay * (2 ** attempt))  # æŒ‡æ•°é€€é¿
            return None
        return wrapper
    return decorator
```

### 3. æ•°æ®ç¼“å­˜ç­–ç•¥
```python
class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self):
        self.cache = {}
        self.cache_ttl = {
            "price_data": 60,      # 1åˆ†é’Ÿ
            "fundamental_data": 3600,  # 1å°æ—¶
            "news_data": 1800,     # 30åˆ†é’Ÿ
            "social_data": 900     # 15åˆ†é’Ÿ
        }
    
    def get(self, key: str, data_type: str) -> Optional[Dict]:
        """è·å–ç¼“å­˜æ•°æ®"""
        if key in self.cache:
            cached_item = self.cache[key]
            ttl = self.cache_ttl.get(data_type, 3600)
            
            if time.time() - cached_item["timestamp"] < ttl:
                return cached_item["data"]
            else:
                del self.cache[key]
        
        return None
    
    def set(self, key: str, data: Dict, data_type: str):
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        self.cache[key] = {
            "data": data,
            "timestamp": time.time(),
            "type": data_type
        }
```

é€šè¿‡è¿™äº›æ•°æ®æºçš„é›†æˆï¼ŒTradingAgents èƒ½å¤Ÿè·å¾—å…¨é¢ã€å®æ—¶ã€é«˜è´¨é‡çš„å¸‚åœºæ•°æ®ï¼Œä¸ºæ™ºèƒ½ä½“çš„åˆ†æå’Œå†³ç­–æä¾›åšå®çš„æ•°æ®åŸºç¡€ã€‚
