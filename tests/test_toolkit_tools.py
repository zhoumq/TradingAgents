#!/usr/bin/env python3
"""
æµ‹è¯•å·¥å…·åŒ…ä¸­çš„Googleå’ŒRedditå·¥å…·
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(project_root / ".env", override=True)

def test_toolkit_tools():
    """æµ‹è¯•å·¥å…·åŒ…ä¸­çš„å·¥å…·"""
    try:
        print("ğŸ§ª æµ‹è¯•å·¥å…·åŒ…ä¸­çš„Googleå’ŒRedditå·¥å…·")
        print("=" * 60)
        
        # æ­£ç¡®å¯¼å…¥Toolkit
        from tradingagents.agents.utils.agent_utils import Toolkit
        from tradingagents.default_config import DEFAULT_CONFIG
        
        # åˆ›å»ºé…ç½®
        config = DEFAULT_CONFIG.copy()
        config["online_tools"] = True
        
        # åˆ›å»ºå·¥å…·åŒ…å®ä¾‹
        toolkit = Toolkit(config=config)
        
        print("âœ… Toolkitå®ä¾‹åˆ›å»ºæˆåŠŸ")
        
        # æ£€æŸ¥æ‰€æœ‰å¯ç”¨æ–¹æ³•
        all_methods = [method for method in dir(toolkit) if not method.startswith('_')]
        print(f"ğŸ“Š å·¥å…·åŒ…æ€»æ–¹æ³•æ•°: {len(all_methods)}")
        
        # æŸ¥æ‰¾Googleç›¸å…³æ–¹æ³•
        google_methods = [m for m in all_methods if 'google' in m.lower()]
        print(f"ğŸ” Googleç›¸å…³æ–¹æ³•: {google_methods}")
        
        # æŸ¥æ‰¾Redditç›¸å…³æ–¹æ³•
        reddit_methods = [m for m in all_methods if 'reddit' in m.lower()]
        print(f"ğŸ” Redditç›¸å…³æ–¹æ³•: {reddit_methods}")
        
        # æŸ¥æ‰¾æ–°é—»ç›¸å…³æ–¹æ³•
        news_methods = [m for m in all_methods if 'news' in m.lower()]
        print(f"ğŸ“° æ–°é—»ç›¸å…³æ–¹æ³•: {news_methods}")
        
        # æµ‹è¯•å…·ä½“çš„Googleå·¥å…·
        if hasattr(toolkit, 'get_google_news'):
            print("\nâœ… get_google_news æ–¹æ³•å­˜åœ¨")
            try:
                # æµ‹è¯•è°ƒç”¨
                print("ğŸ“° æµ‹è¯•Googleæ–°é—»è·å–...")
                news = toolkit.get_google_news(
                    query="Apple AAPL",
                    curr_date="2025-06-27",
                    look_back_days=3
                )
                if news and len(news) > 100:
                    print(f"âœ… Googleæ–°é—»è·å–æˆåŠŸ ({len(news)} å­—ç¬¦)")
                else:
                    print("âš ï¸ Googleæ–°é—»è·å–æˆåŠŸä½†å†…å®¹è¾ƒå°‘")
            except Exception as e:
                print(f"âŒ Googleæ–°é—»æµ‹è¯•å¤±è´¥: {e}")
        else:
            print("âŒ get_google_news æ–¹æ³•ä¸å­˜åœ¨")
        
        # æµ‹è¯•Redditå·¥å…·
        reddit_tools = ['get_reddit_global_news', 'get_reddit_company_news', 'get_reddit_stock_info', 'get_reddit_news']
        
        for tool_name in reddit_tools:
            if hasattr(toolkit, tool_name):
                print(f"âœ… {tool_name} æ–¹æ³•å­˜åœ¨")
            else:
                print(f"âŒ {tool_name} æ–¹æ³•ä¸å­˜åœ¨")
        
        # æ˜¾ç¤ºæ‰€æœ‰æ–¹æ³•ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        print(f"\nğŸ“‹ æ‰€æœ‰å¯ç”¨æ–¹æ³•:")
        for i, method in enumerate(sorted(all_methods), 1):
            print(f"  {i:2d}. {method}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å·¥å…·åŒ…æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        print(traceback.format_exc())
        return False

def test_social_news_analysts():
    """æµ‹è¯•ç¤¾äº¤åª’ä½“å’Œæ–°é—»åˆ†æå¸ˆæ˜¯å¦èƒ½ä½¿ç”¨è¿™äº›å·¥å…·"""
    try:
        print("\nğŸ§ª æµ‹è¯•åˆ†æå¸ˆå·¥å…·é›†æˆ")
        print("=" * 60)
        
        # æ£€æŸ¥ç¤¾äº¤åª’ä½“åˆ†æå¸ˆ
        try:
            from tradingagents.agents.analysts.social_media_analyst import create_social_media_analyst
            print("âœ… ç¤¾äº¤åª’ä½“åˆ†æå¸ˆæ¨¡å—å¯ç”¨")
        except ImportError as e:
            print(f"âŒ ç¤¾äº¤åª’ä½“åˆ†æå¸ˆå¯¼å…¥å¤±è´¥: {e}")
        
        # æ£€æŸ¥æ–°é—»åˆ†æå¸ˆ
        try:
            from tradingagents.agents.analysts.news_analyst import create_news_analyst
            print("âœ… æ–°é—»åˆ†æå¸ˆæ¨¡å—å¯ç”¨")
        except ImportError as e:
            print(f"âŒ æ–°é—»åˆ†æå¸ˆå¯¼å…¥å¤±è´¥: {e}")
        
        return True
        
    except Exception as e:
        print(f"âŒ åˆ†æå¸ˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def check_data_requirements():
    """æ£€æŸ¥æ•°æ®è¦æ±‚"""
    print("\nğŸ§ª æ£€æŸ¥æ•°æ®è¦æ±‚")
    print("=" * 60)
    
    # æ£€æŸ¥Redditæ•°æ®ç›®å½•
    reddit_data_paths = [
        "tradingagents/dataflows/data_cache/reddit_data",
        "data/reddit_data",
        "reddit_data"
    ]
    
    reddit_data_found = False
    for path in reddit_data_paths:
        reddit_path = Path(path)
        if reddit_path.exists():
            print(f"âœ… Redditæ•°æ®ç›®å½•æ‰¾åˆ°: {reddit_path}")
            subdirs = [d.name for d in reddit_path.iterdir() if d.is_dir()]
            if subdirs:
                print(f"   å­ç›®å½•: {subdirs}")
                reddit_data_found = True
            else:
                print("   ç›®å½•ä¸ºç©º")
            break
    
    if not reddit_data_found:
        print("âš ï¸ Redditæ•°æ®ç›®å½•æœªæ‰¾åˆ°")
        print("ğŸ’¡ Redditå·¥å…·éœ€è¦é¢„å…ˆä¸‹è½½çš„æ•°æ®æ–‡ä»¶")
        print("   å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
        print("   1. ä¸‹è½½Redditæ•°æ®é›†")
        print("   2. é…ç½®æ­£ç¡®çš„æ•°æ®è·¯å¾„")
        print("   3. ä½¿ç”¨åœ¨çº¿Reddit APIï¼ˆå¦‚æœæ”¯æŒï¼‰")
    
    # æ£€æŸ¥Google APIè¦æ±‚
    google_key = os.getenv('GOOGLE_API_KEY')
    if google_key:
        print("âœ… Google APIå¯†é’¥å·²é…ç½®")
        print("ğŸ’¡ Googleæ–°é—»å·¥å…·ä½¿ç”¨ç½‘é¡µæŠ“å–ï¼Œä¸éœ€è¦APIå¯†é’¥")
    else:
        print("âš ï¸ Google APIå¯†é’¥æœªé…ç½®")
        print("ğŸ’¡ ä½†Googleæ–°é—»å·¥å…·ä»å¯èƒ½æ­£å¸¸å·¥ä½œï¼ˆä½¿ç”¨ç½‘é¡µæŠ“å–ï¼‰")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª å·¥å…·åŒ…Googleå’ŒRedditå·¥å…·æµ‹è¯•")
    print("=" * 70)
    
    # æ£€æŸ¥APIå¯†é’¥çŠ¶æ€
    print("ğŸ”‘ APIå¯†é’¥çŠ¶æ€:")
    google_key = os.getenv('GOOGLE_API_KEY')
    reddit_id = os.getenv('REDDIT_CLIENT_ID')
    print(f"   Google API: {'âœ… å·²é…ç½®' if google_key else 'âŒ æœªé…ç½®'}")
    print(f"   Reddit API: {'âœ… å·²é…ç½®' if reddit_id else 'âŒ æœªé…ç½®'}")
    
    # è¿è¡Œæµ‹è¯•
    results = {}
    
    results['å·¥å…·åŒ…å·¥å…·'] = test_toolkit_tools()
    results['åˆ†æå¸ˆé›†æˆ'] = test_social_news_analysts()
    
    # æ£€æŸ¥æ•°æ®è¦æ±‚
    check_data_requirements()
    
    # æ€»ç»“ç»“æœ
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    print("=" * 50)
    
    for test_name, success in results.items():
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"  {test_name}: {status}")
    
    successful_tests = sum(results.values())
    total_tests = len(results)
    
    print(f"\nğŸ¯ æ€»ä½“ç»“æœ: {successful_tests}/{total_tests} æµ‹è¯•é€šè¿‡")

if __name__ == "__main__":
    main()
