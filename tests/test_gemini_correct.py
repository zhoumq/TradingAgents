#!/usr/bin/env python3
"""
ä½¿ç”¨æ­£ç¡®çš„æ¨¡å‹åç§°æµ‹è¯•Gemini
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(project_root / ".env", override=True)

# æ¨èçš„æ¨¡å‹åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
RECOMMENDED_MODELS = [
    "gemini-2.0-flash",      # æœ€æ–°çš„2.0ç‰ˆæœ¬
    "gemini-1.5-flash",      # ç¨³å®šçš„1.5ç‰ˆæœ¬
    "gemini-1.5-pro",        # æ›´å¼ºå¤§çš„1.5ç‰ˆæœ¬
    "gemini-2.5-flash",      # 2.5ç‰ˆæœ¬
]

def test_model(model_name):
    """æµ‹è¯•ç‰¹å®šæ¨¡å‹"""
    try:
        print(f"\nğŸ§ª æµ‹è¯•æ¨¡å‹: {model_name}")
        print("=" * 60)
        
        import google.generativeai as genai
        from langchain_google_genai import ChatGoogleGenerativeAI
        
        # é…ç½®APIå¯†é’¥
        google_api_key = os.getenv('GOOGLE_API_KEY')
        genai.configure(api_key=google_api_key)
        
        # æµ‹è¯•1: ç›´æ¥API
        print("ğŸ“ æµ‹è¯•ç›´æ¥API...")
        try:
            model = genai.GenerativeModel(model_name)
            response = model.generate_content("è¯·ç”¨ä¸­æ–‡ç®€å•ä»‹ç»ä¸€ä¸‹è‹¹æœå…¬å¸çš„ä¸»è¦ä¸šåŠ¡")
            
            if response and response.text:
                print("âœ… ç›´æ¥APIè°ƒç”¨æˆåŠŸ")
                print(f"   å“åº”é•¿åº¦: {len(response.text)} å­—ç¬¦")
                print(f"   å“åº”é¢„è§ˆ: {response.text[:150]}...")
                direct_success = True
            else:
                print("âŒ ç›´æ¥APIè°ƒç”¨å¤±è´¥ï¼šæ— å“åº”å†…å®¹")
                direct_success = False
        except Exception as e:
            print(f"âŒ ç›´æ¥APIè°ƒç”¨å¤±è´¥: {e}")
            direct_success = False
        
        # æµ‹è¯•2: LangChainé›†æˆ
        print("\nğŸ“ æµ‹è¯•LangChainé›†æˆ...")
        try:
            llm = ChatGoogleGenerativeAI(
                model=model_name,
                temperature=0.1,
                max_tokens=500,
                google_api_key=google_api_key
            )
            
            response = llm.invoke("è¯·ç”¨ä¸­æ–‡åˆ†æè‹¹æœå…¬å¸çš„æŠ•èµ„ä»·å€¼ï¼ŒåŒ…æ‹¬ä¼˜åŠ¿å’Œé£é™©")
            
            if response and response.content:
                print("âœ… LangChainè°ƒç”¨æˆåŠŸ")
                print(f"   å“åº”é•¿åº¦: {len(response.content)} å­—ç¬¦")
                print(f"   å“åº”é¢„è§ˆ: {response.content[:150]}...")
                langchain_success = True
            else:
                print("âŒ LangChainè°ƒç”¨å¤±è´¥ï¼šæ— å“åº”å†…å®¹")
                langchain_success = False
        except Exception as e:
            print(f"âŒ LangChainè°ƒç”¨å¤±è´¥: {e}")
            langchain_success = False
        
        return direct_success, langchain_success
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        return False, False

def test_tradingagents_with_gemini(model_name):
    """æµ‹è¯•TradingAgentsä¸­ä½¿ç”¨Gemini"""
    try:
        print(f"\nğŸ§ª æµ‹è¯•TradingAgentsä¸­ä½¿ç”¨ {model_name}")
        print("=" * 60)
        
        from tradingagents.graph.trading_graph import TradingAgentsGraph
        from tradingagents.default_config import DEFAULT_CONFIG
        
        # åˆ›å»ºä½¿ç”¨Geminiçš„é…ç½®
        config = DEFAULT_CONFIG.copy()
        config["llm_provider"] = "google"
        config["deep_think_llm"] = model_name
        config["quick_think_llm"] = model_name
        config["online_tools"] = True
        config["memory_enabled"] = True
        
        # ä¿®å¤è·¯å¾„
        config["data_dir"] = str(project_root / "data")
        config["results_dir"] = str(project_root / "results")
        config["data_cache_dir"] = str(project_root / "tradingagents" / "dataflows" / "data_cache")
        
        # åˆ›å»ºç›®å½•
        os.makedirs(config["data_dir"], exist_ok=True)
        os.makedirs(config["results_dir"], exist_ok=True)
        os.makedirs(config["data_cache_dir"], exist_ok=True)
        
        print("âœ… é…ç½®åˆ›å»ºæˆåŠŸ")
        print(f"   æ¨¡å‹: {model_name}")
        
        # åˆ›å»ºTradingAgentsGraphå®ä¾‹
        print("ğŸš€ åˆå§‹åŒ–TradingAgentså›¾...")
        graph = TradingAgentsGraph(["market"], config=config, debug=False)
        
        print("âœ… TradingAgentså›¾åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•ç®€å•åˆ†æ
        print("ğŸ“Š æµ‹è¯•è‚¡ç¥¨åˆ†æ...")
        try:
            state, decision = graph.propagate("AAPL", "2025-06-27")
            
            if state and decision:
                print("âœ… Geminié©±åŠ¨çš„è‚¡ç¥¨åˆ†ææˆåŠŸ")
                print(f"   å†³ç­–ç»“æœ: {decision}")
                
                # æ£€æŸ¥å¸‚åœºæŠ¥å‘Š
                if "market_report" in state and state["market_report"]:
                    market_report = state["market_report"]
                    print(f"   å¸‚åœºæŠ¥å‘Šé•¿åº¦: {len(market_report)} å­—ç¬¦")
                    print(f"   æŠ¥å‘Šé¢„è§ˆ: {market_report[:150]}...")
                
                return True
            else:
                print("âŒ åˆ†æå®Œæˆä½†ç»“æœä¸ºç©º")
                return False
                
        except Exception as e:
            print(f"âŒ è‚¡ç¥¨åˆ†æå¤±è´¥: {e}")
            return False
            
    except Exception as e:
        print(f"âŒ TradingAgentsé›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª Geminiæ¨¡å‹å®Œæ•´æµ‹è¯•")
    print("=" * 70)
    
    # æ£€æŸ¥APIå¯†é’¥
    google_api_key = os.getenv('GOOGLE_API_KEY')
    if not google_api_key:
        print("âŒ Google APIå¯†é’¥æœªé…ç½®")
        return
    
    print(f"âœ… Google APIå¯†é’¥å·²é…ç½®: {google_api_key[:20]}...")
    
    # æµ‹è¯•æ¨èçš„æ¨¡å‹
    best_model = None
    best_score = 0
    
    for model_name in RECOMMENDED_MODELS:
        print(f"\n{'='*70}")
        print(f"ğŸ¯ æµ‹è¯•æ¨¡å‹: {model_name}")
        
        direct_success, langchain_success = test_model(model_name)
        
        # è®¡ç®—å¾—åˆ†
        score = int(direct_success) + int(langchain_success)
        
        print(f"\nğŸ“Š {model_name} æµ‹è¯•ç»“æœ:")
        print(f"   ç›´æ¥API: {'âœ… é€šè¿‡' if direct_success else 'âŒ å¤±è´¥'}")
        print(f"   LangChain: {'âœ… é€šè¿‡' if langchain_success else 'âŒ å¤±è´¥'}")
        print(f"   å¾—åˆ†: {score}/2")
        
        if score > best_score:
            best_score = score
            best_model = model_name
        
        # å¦‚æœæ‰¾åˆ°å®Œå…¨å¯ç”¨çš„æ¨¡å‹ï¼Œå°±ä½¿ç”¨å®ƒ
        if score == 2:
            print(f"\nğŸ‰ æ‰¾åˆ°å®Œå…¨å¯ç”¨çš„æ¨¡å‹: {model_name}")
            break
    
    # ä½¿ç”¨æœ€ä½³æ¨¡å‹æµ‹è¯•TradingAgents
    if best_model and best_score > 0:
        print(f"\n{'='*70}")
        print(f"ğŸ† ä½¿ç”¨æœ€ä½³æ¨¡å‹æµ‹è¯•TradingAgents: {best_model}")
        
        tradingagents_success = test_tradingagents_with_gemini(best_model)
        
        # æœ€ç»ˆæ€»ç»“
        print(f"\nğŸ“Š æœ€ç»ˆæµ‹è¯•ç»“æœæ€»ç»“:")
        print("=" * 50)
        print(f"  æœ€ä½³æ¨¡å‹: {best_model}")
        print(f"  åŸºç¡€åŠŸèƒ½å¾—åˆ†: {best_score}/2")
        print(f"  TradingAgentsé›†æˆ: {'âœ… é€šè¿‡' if tradingagents_success else 'âŒ å¤±è´¥'}")
        
        if best_score == 2 and tradingagents_success:
            print(f"\nğŸ‰ Geminiæ¨¡å‹ {best_model} å®Œå…¨å¯ç”¨ï¼")
            print(f"\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
            print(f"   1. åœ¨Webç•Œé¢é…ç½®ä¸­é€‰æ‹©Googleä½œä¸ºLLMæä¾›å•†")
            print(f"   2. ä½¿ç”¨æ¨¡å‹åç§°: {best_model}")
            print(f"   3. å¯ä»¥è¿›è¡Œå®Œæ•´çš„è‚¡ç¥¨åˆ†æ")
            print(f"   4. æ”¯æŒä¸­æ–‡è¾“å…¥å’Œè¾“å‡º")
        else:
            print(f"\nâš ï¸ æ¨¡å‹éƒ¨åˆ†å¯ç”¨ï¼Œå»ºè®®æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIé…é¢")
    else:
        print(f"\nâŒ æ‰€æœ‰æ¨èæ¨¡å‹éƒ½ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥å’Œç½‘ç»œè¿æ¥")

if __name__ == "__main__":
    main()
