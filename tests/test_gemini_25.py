#!/usr/bin/env python3
"""
æµ‹è¯•Gemini 2.5 Flashå’ŒProæ¨¡å‹
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(project_root / ".env", override=True)

# Gemini 2.5æ¨¡å‹åˆ—è¡¨
GEMINI_25_MODELS = [
    "gemini-2.5-flash",
    "gemini-2.5-pro", 
    "gemini-2.5-flash-002",
    "gemini-2.5-pro-002"
]

def test_gemini_25_availability():
    """æµ‹è¯•Gemini 2.5æ¨¡å‹çš„å¯ç”¨æ€§"""
    print("ğŸ§ª æµ‹è¯•Gemini 2.5æ¨¡å‹å¯ç”¨æ€§")
    print("=" * 60)
    
    try:
        import google.generativeai as genai
        
        # é…ç½®APIå¯†é’¥
        google_api_key = os.getenv('GOOGLE_API_KEY')
        if not google_api_key:
            print("âŒ Google APIå¯†é’¥æœªé…ç½®")
            return []
        
        genai.configure(api_key=google_api_key)
        
        # è·å–æ‰€æœ‰å¯ç”¨æ¨¡å‹
        print("ğŸ“‹ è·å–æ‰€æœ‰å¯ç”¨æ¨¡å‹...")
        all_models = genai.list_models()
        
        available_25_models = []
        
        print("ğŸ” æ£€æŸ¥Gemini 2.5æ¨¡å‹:")
        for model_name in GEMINI_25_MODELS:
            found = False
            for model in all_models:
                if model_name in model.name:
                    print(f"âœ… {model_name}: å¯ç”¨")
                    print(f"   å®Œæ•´åç§°: {model.name}")
                    print(f"   æ˜¾ç¤ºåç§°: {model.display_name}")
                    print(f"   æ”¯æŒæ–¹æ³•: {model.supported_generation_methods}")
                    available_25_models.append(model.name)
                    found = True
                    break
            
            if not found:
                print(f"âŒ {model_name}: ä¸å¯ç”¨")
        
        return available_25_models
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥æ¨¡å‹å¯ç”¨æ€§å¤±è´¥: {e}")
        return []

def test_specific_gemini_25_model(model_name):
    """æµ‹è¯•ç‰¹å®šçš„Gemini 2.5æ¨¡å‹"""
    try:
        print(f"\nğŸ§ª æµ‹è¯•æ¨¡å‹: {model_name}")
        print("=" * 60)
        
        import google.generativeai as genai
        from langchain_google_genai import ChatGoogleGenerativeAI
        
        # é…ç½®APIå¯†é’¥
        google_api_key = os.getenv('GOOGLE_API_KEY')
        genai.configure(api_key=google_api_key)
        
        # æµ‹è¯•1: ç›´æ¥API
        print("ğŸ“ æµ‹è¯•ç›´æ¥API...")
        try:
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(
                "è¯·ç”¨ä¸­æ–‡åˆ†æè‹¹æœå…¬å¸(AAPL)çš„æŠ•èµ„ä»·å€¼ï¼ŒåŒ…æ‹¬æŠ€æœ¯åˆ›æ–°ã€å¸‚åœºåœ°ä½å’Œè´¢åŠ¡çŠ¶å†µ"
            )
            
            if response and response.text:
                print("âœ… ç›´æ¥APIè°ƒç”¨æˆåŠŸ")
                print(f"   å“åº”é•¿åº¦: {len(response.text)} å­—ç¬¦")
                print(f"   å“åº”é¢„è§ˆ: {response.text[:200]}...")
                direct_success = True
            else:
                print("âŒ ç›´æ¥APIè°ƒç”¨å¤±è´¥ï¼šæ— å“åº”å†…å®¹")
                direct_success = False
        except Exception as e:
            print(f"âŒ ç›´æ¥APIè°ƒç”¨å¤±è´¥: {e}")
            direct_success = False
        
        # æµ‹è¯•2: LangChainé›†æˆ
        print("\nğŸ“ æµ‹è¯•LangChainé›†æˆ...")
        try:
            llm = ChatGoogleGenerativeAI(
                model=model_name,
                temperature=0.1,
                max_tokens=1000,
                google_api_key=google_api_key
            )
            
            response = llm.invoke(
                "è¯·ç”¨ä¸­æ–‡åˆ†æå½“å‰äººå·¥æ™ºèƒ½è¡Œä¸šçš„æŠ•èµ„æœºä¼šï¼Œé‡ç‚¹å…³æ³¨å¤§å‹ç§‘æŠ€å…¬å¸çš„AIæˆ˜ç•¥"
            )
            
            if response and response.content:
                print("âœ… LangChainè°ƒç”¨æˆåŠŸ")
                print(f"   å“åº”é•¿åº¦: {len(response.content)} å­—ç¬¦")
                print(f"   å“åº”é¢„è§ˆ: {response.content[:200]}...")
                langchain_success = True
            else:
                print("âŒ LangChainè°ƒç”¨å¤±è´¥ï¼šæ— å“åº”å†…å®¹")
                langchain_success = False
        except Exception as e:
            print(f"âŒ LangChainè°ƒç”¨å¤±è´¥: {e}")
            langchain_success = False
        
        # æµ‹è¯•3: å¤æ‚æ¨ç†èƒ½åŠ›
        print("\nğŸ“ æµ‹è¯•å¤æ‚æ¨ç†èƒ½åŠ›...")
        try:
            complex_prompt = """
            è¯·ç”¨ä¸­æ–‡è¿›è¡Œå¤æ‚çš„è‚¡ç¥¨åˆ†ææ¨ç†ï¼š
            
            å‡è®¾åœºæ™¯ï¼š
            - å½“å‰æ—¶é—´ï¼š2025å¹´6æœˆ
            - ç¾è”å‚¨åˆšåˆšé™æ¯0.25%
            - ä¸­ç¾è´¸æ˜“å…³ç³»æœ‰æ‰€ç¼“è§£
            - AIæŠ€æœ¯å¿«é€Ÿå‘å±•
            - é€šèƒ€ç‡é™è‡³2.5%
            
            è¯·åˆ†æåœ¨è¿™ç§å®è§‚ç¯å¢ƒä¸‹ï¼Œè‹¹æœå…¬å¸(AAPL)çš„æŠ•èµ„ä»·å€¼ï¼ŒåŒ…æ‹¬ï¼š
            1. å®è§‚ç»æµå› ç´ çš„å½±å“
            2. è¡Œä¸šç«äº‰æ€åŠ¿
            3. å…¬å¸ç‰¹æœ‰ä¼˜åŠ¿
            4. é£é™©å› ç´ 
            5. æŠ•èµ„å»ºè®®å’Œç›®æ ‡ä»·ä½
            
            è¯·æä¾›è¯¦ç»†çš„é€»è¾‘æ¨ç†è¿‡ç¨‹ã€‚
            """
            
            response = llm.invoke(complex_prompt)
            
            if response and response.content and len(response.content) > 500:
                print("âœ… å¤æ‚æ¨ç†æµ‹è¯•æˆåŠŸ")
                print(f"   å“åº”é•¿åº¦: {len(response.content)} å­—ç¬¦")
                print(f"   å“åº”é¢„è§ˆ: {response.content[:300]}...")
                complex_success = True
            else:
                print("âŒ å¤æ‚æ¨ç†æµ‹è¯•å¤±è´¥ï¼šå“åº”è¿‡çŸ­æˆ–æ— å†…å®¹")
                complex_success = False
        except Exception as e:
            print(f"âŒ å¤æ‚æ¨ç†æµ‹è¯•å¤±è´¥: {e}")
            complex_success = False
        
        return direct_success, langchain_success, complex_success
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        return False, False, False

def test_gemini_25_in_tradingagents(model_name):
    """æµ‹è¯•Gemini 2.5åœ¨TradingAgentsä¸­çš„ä½¿ç”¨"""
    try:
        print(f"\nğŸ§ª æµ‹è¯•{model_name}åœ¨TradingAgentsä¸­çš„ä½¿ç”¨")
        print("=" * 60)
        
        from tradingagents.graph.trading_graph import TradingAgentsGraph
        from tradingagents.default_config import DEFAULT_CONFIG
        
        # åˆ›å»ºé…ç½®
        config = DEFAULT_CONFIG.copy()
        config["llm_provider"] = "google"
        config["deep_think_llm"] = model_name
        config["quick_think_llm"] = model_name
        config["online_tools"] = False  # é¿å…APIé™åˆ¶
        config["memory_enabled"] = True  # å¯ç”¨å†…å­˜åŠŸèƒ½
        config["max_debate_rounds"] = 1
        config["max_risk_discuss_rounds"] = 1
        
        # ä¿®å¤è·¯å¾„
        config["data_dir"] = str(project_root / "data")
        config["results_dir"] = str(project_root / "results")
        config["data_cache_dir"] = str(project_root / "tradingagents" / "dataflows" / "data_cache")
        
        # åˆ›å»ºç›®å½•
        os.makedirs(config["data_dir"], exist_ok=True)
        os.makedirs(config["results_dir"], exist_ok=True)
        os.makedirs(config["data_cache_dir"], exist_ok=True)
        
        print("âœ… é…ç½®åˆ›å»ºæˆåŠŸ")
        print(f"   æ¨¡å‹: {model_name}")
        print(f"   å†…å­˜åŠŸèƒ½: {config['memory_enabled']}")
        
        # åˆ›å»ºTradingAgentsGraphå®ä¾‹
        print("ğŸš€ åˆå§‹åŒ–TradingAgentså›¾...")
        graph = TradingAgentsGraph(["market"], config=config, debug=False)
        
        print("âœ… TradingAgentså›¾åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•åˆ†æ
        print("ğŸ“Š å¼€å§‹è‚¡ç¥¨åˆ†æ...")
        
        try:
            state, decision = graph.propagate("AAPL", "2025-06-27")
            
            if state and decision:
                print(f"âœ… {model_name}é©±åŠ¨çš„è‚¡ç¥¨åˆ†ææˆåŠŸï¼")
                print(f"   æœ€ç»ˆå†³ç­–: {decision}")
                
                # æ£€æŸ¥å¸‚åœºæŠ¥å‘Š
                if "market_report" in state and state["market_report"]:
                    market_report = state["market_report"]
                    print(f"   å¸‚åœºæŠ¥å‘Šé•¿åº¦: {len(market_report)} å­—ç¬¦")
                    print(f"   æŠ¥å‘Šé¢„è§ˆ: {market_report[:200]}...")
                
                return True
            else:
                print("âŒ åˆ†æå®Œæˆä½†ç»“æœä¸ºç©º")
                return False
                
        except Exception as e:
            print(f"âŒ è‚¡ç¥¨åˆ†æå¤±è´¥: {e}")
            return False
            
    except Exception as e:
        print(f"âŒ TradingAgentsæµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª Gemini 2.5æ¨¡å‹æµ‹è¯•")
    print("=" * 70)
    
    # æ£€æŸ¥APIå¯†é’¥
    google_api_key = os.getenv('GOOGLE_API_KEY')
    if not google_api_key:
        print("âŒ Google APIå¯†é’¥æœªé…ç½®")
        return
    
    print(f"âœ… Google APIå¯†é’¥å·²é…ç½®: {google_api_key[:20]}...")
    
    # æ£€æŸ¥å¯ç”¨çš„Gemini 2.5æ¨¡å‹
    available_models = test_gemini_25_availability()
    
    if not available_models:
        print("\nâŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„Gemini 2.5æ¨¡å‹")
        return
    
    print(f"\nğŸ¯ æ‰¾åˆ° {len(available_models)} ä¸ªå¯ç”¨çš„Gemini 2.5æ¨¡å‹")
    
    # æµ‹è¯•æ¯ä¸ªå¯ç”¨æ¨¡å‹
    best_model = None
    best_score = 0
    
    for model_name in available_models:
        print(f"\n{'='*70}")
        
        # åŸºç¡€åŠŸèƒ½æµ‹è¯•
        direct, langchain, complex = test_specific_gemini_25_model(model_name)
        score = sum([direct, langchain, complex])
        
        print(f"\nğŸ“Š {model_name} åŸºç¡€æµ‹è¯•ç»“æœ:")
        print(f"   ç›´æ¥API: {'âœ…' if direct else 'âŒ'}")
        print(f"   LangChain: {'âœ…' if langchain else 'âŒ'}")
        print(f"   å¤æ‚æ¨ç†: {'âœ…' if complex else 'âŒ'}")
        print(f"   å¾—åˆ†: {score}/3")
        
        if score > best_score:
            best_score = score
            best_model = model_name
        
        # å¦‚æœåŸºç¡€åŠŸèƒ½å…¨éƒ¨é€šè¿‡ï¼Œæµ‹è¯•TradingAgentsé›†æˆ
        if score == 3:
            tradingagents_success = test_gemini_25_in_tradingagents(model_name)
            if tradingagents_success:
                print(f"   TradingAgents: âœ…")
                total_score = score + 1
            else:
                print(f"   TradingAgents: âŒ")
                total_score = score
            
            print(f"   æ€»å¾—åˆ†: {total_score}/4")
    
    # æœ€ç»ˆæ¨è
    print(f"\nğŸ“Š æœ€ç»ˆæµ‹è¯•ç»“æœ:")
    print("=" * 50)
    print(f"  æœ€ä½³æ¨¡å‹: {best_model}")
    print(f"  æœ€é«˜å¾—åˆ†: {best_score}/3")
    
    if best_score >= 2:
        print(f"\nğŸ‰ æ¨èä½¿ç”¨: {best_model}")
        print(f"\nğŸ’¡ é…ç½®å»ºè®®:")
        print(f"   1. åœ¨Webç•Œé¢ä¸­é€‰æ‹©'Google'ä½œä¸ºLLMæä¾›å•†")
        print(f"   2. ä½¿ç”¨æ¨¡å‹åç§°: {best_model}")
        print(f"   3. Gemini 2.5å…·æœ‰æ›´å¼ºçš„æ¨ç†å’Œåˆ†æèƒ½åŠ›")
        print(f"   4. æ”¯æŒæ›´å¤æ‚çš„é‡‘èåˆ†æä»»åŠ¡")
    else:
        print(f"\nâš ï¸ æ‰€æœ‰Gemini 2.5æ¨¡å‹æµ‹è¯•ä¸ç†æƒ³")
        print(f"   å»ºè®®æ£€æŸ¥APIå¯†é’¥æƒé™å’Œç½‘ç»œè¿æ¥")

if __name__ == "__main__":
    main()
